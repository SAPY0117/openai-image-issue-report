# 📂 OpenAI-Service-Issue-Log

A public user report documenting recurring UX and billing issues on OpenAI’s image generation platform (DALL·E). This is not a rant, but a structured feedback submission intended to highlight critical product and policy shortcomings, and to advocate for actionable improvements.

---

## 📌 Key Issues

### 1. 🔄 Prompt Disregard: Incorrect Number of People
- **Expected:** "Generate an image with 3 people."
- **Actual Output:** Often renders 4+ individuals.
- **Impact:** Users are charged despite prompt deviation.
- **User Burden:** Manual retries, wasted credits.

### 2. ⚠️ Unsolicited Image Generation
- **Behavior:** Image generation begins while prompt is still being edited.
- **No Confirmation Step:** Credit deducted without explicit user action.

### 3. 💸 No Refund or Error Recovery System
- **Consequence:** Credits are lost without any automated recourse.
- **Support Limitations:** Manual contact is burdensome and inconsistent.

---

## 💡 User Feedback Excerpts
> “AI’s ethical standards are replacing human common sense without consent.”  
> “Is this technological advancement, or just unilateral enforcement of opaque rules?”  
> “There’s no way to report systemic failure unless users become their own QA department.”

---

## 🛠 Suggested Improvements

### 1. **System Feedback Channel**
Add a simple, context-aware **‘Report This Issue’** button that auto-attaches metadata from each image/chat session.

### 2. **Policy Confirmation Dialogs**
Before blocking content generation (e.g., for nudity or violence), provide a notice:  
`"This request may violate policy. Continue anyway? [Yes] [No]"`

### 3. **Credit Restoration Logic**
Automate credit refunds when prompts are clearly misinterpreted, especially with objective instructions like number of figures.

### 4. **Audit for Ethical Consistency**
Review and publish criteria used for policy-based content blocks vs. permitted gray-area content (e.g., religious imagery).

---

## 📣 Meta Issue: Economic vs. Content Ethics
> Content moderation is strict. But repeated credit loss and system mistakes are treated as user problems.  
> If fairness applies to content, it must also apply to cost.

---

## 📎 Purpose
To improve transparency, fairness, and user experience in AI-assisted platforms. Shared publicly to encourage responsible AI practices across the industry.

---

## 📅 Date: April 2025  
## 🧾 Author: A paying user from South Korea

